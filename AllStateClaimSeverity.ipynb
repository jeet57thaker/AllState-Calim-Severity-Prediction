{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllState Claim Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(type(train))\n",
    "train.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Categorical variables to Numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe with only categorical variables to convert them into numerical using hot code encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns satrting with 'cat' and form a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitIntoCatAndCont(features):\n",
    "    cat_col_list = []\n",
    "    cont_col_list = []\n",
    "    for i in features:\n",
    "        if i.startswith(\"cat\"):\n",
    "            cat_col_list.append(i)\n",
    "        else:\n",
    "            cont_col_list.append(i)\n",
    "            \n",
    "    return cat_col_list, cont_col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert lists to dataframes of 'cat' and 'col'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitDataFrameIntoCatAndCol (data_frame, train_cat_col_list, train_cont_col_list):\n",
    "    cat_col_df = pd.DataFrame(data_frame, columns = train_cat_col_list)\n",
    "    cont_col_df = pd.DataFrame(data_frame, columns = train_cont_col_list)\n",
    "    return cat_col_df, cont_col_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LabelEncoder(categoricalData, continuousData):\n",
    "    # Categorical Feature Analysis\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    catFeatures = []\n",
    "    for colName in categoricalData.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(categoricalData[colName].unique())\n",
    "        categoricalData[colName] = le.transform(categoricalData[colName])\n",
    "        \n",
    "    encoded_train_data = categoricalData.join(continuousData)\n",
    "    #encoded_train_data = pd.concat(categoricalData, continuousData, axis = 1, ignore_index = True)\n",
    "    return encoded_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def cross_validation(total_samples, n_folds, X, Y, clf):\n",
    "    accuracy = []\n",
    "    kf = KFold(total_samples, n_folds, True) #Shuffle = True\n",
    "    \n",
    "    for train_index, test_index in kf:\n",
    "        #print(\"TRAIN: \", train_index, \"TEST: \", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy.append(mean_squared_error(y_test, predictions))\n",
    "        print(accuracy)\n",
    "        \n",
    "    return clf, np.array(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the features (except response feature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "def normalize(X):\n",
    "    scale(X, axis = 0, with_mean = True, with_std = True, copy = True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands to execute for training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X\n",
      "(188318, 130)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "features = list(train.columns.values)\n",
    "\n",
    "# cat_col_list, cont_col_list\n",
    "\n",
    "train_cat_col_list, train_cont_col_list = SplitIntoCatAndCont(features)\n",
    "\n",
    "\n",
    "train_cat_col_df, train_cont_col_df = SplitDataFrameIntoCatAndCol(train, train_cat_col_list, train_cont_col_list)\n",
    "\n",
    "train_feature_df = LabelEncoder(train_cat_col_df, train_cont_col_df)\n",
    "\n",
    "train_feature = np.array(train_feature_df)\n",
    "r, c = train_feature.shape\n",
    "\n",
    "# Create an array with index of columns\n",
    "i_cols = []\n",
    "for i in range(0, c-1):\n",
    "    i_cols.append(i)\n",
    "    \n",
    "# Y is the target column, rest goes in X\n",
    "X_train = train_feature[:, 0:(c-1)]\n",
    "y_train = train_feature[:, (c-1)]\n",
    "\n",
    "# Normalizaation of Features\n",
    "X_train = normalize(X_train)\n",
    "\n",
    "X_all = []\n",
    "\n",
    "X_all.append([i_cols])\n",
    "\n",
    "print(\"Shape of X\")\n",
    "print(X_train.shape)\n",
    "print(type(X_train))\n",
    "print(type(train_feature_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129]\n",
      "['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat20', 'cat21', 'cat22', 'cat23', 'cat24', 'cat25', 'cat26', 'cat27', 'cat28', 'cat29', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', 'cat35', 'cat36', 'cat37', 'cat38', 'cat39', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44', 'cat45', 'cat46', 'cat47', 'cat48', 'cat49', 'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56', 'cat57', 'cat58', 'cat59', 'cat60', 'cat61', 'cat62', 'cat63', 'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat70', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77', 'cat78', 'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', 'cat86', 'cat87', 'cat88', 'cat89', 'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98', 'cat99', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', 'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Linear Regression\n",
    "clf = LinearRegression(fit_intercept = True, normalize = True)\n",
    "\n",
    "# RFE\n",
    "selector = RFE(clf, n_features_to_select = 130, step = 1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "print(np.where(selector.support_ == True)[0])\n",
    "\n",
    "featureNames = train_cat_col_list + train_cont_col_list\n",
    "\n",
    "# print(featureNames)\n",
    "\n",
    "finalFeatures = []\n",
    "\n",
    "for num in np.where(selector.support_ == True)[0]:\n",
    "    finalFeatures.append(featureNames[num])\n",
    "\n",
    "print(finalFeatures)\n",
    "print(type(finalFeatures))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10    ...     \\\n",
       "0     0     1     0     1     0     0     0     0     1      0    ...      \n",
       "1     0     1     0     0     0     0     0     0     1      1    ...      \n",
       "2     0     1     0     0     1     0     0     0     1      1    ...      \n",
       "3     1     1     0     1     0     0     0     0     1      0    ...      \n",
       "4     0     1     0     1     0     0     0     0     1      1    ...      \n",
       "\n",
       "      cont5     cont6     cont7    cont8    cont9   cont10    cont11  \\\n",
       "0  0.310061  0.718367  0.335060  0.30260  0.67135  0.83510  0.569745   \n",
       "1  0.885834  0.438917  0.436585  0.60087  0.35127  0.43919  0.338312   \n",
       "2  0.397069  0.289648  0.315545  0.27320  0.26076  0.32446  0.381398   \n",
       "3  0.422268  0.440945  0.391128  0.31796  0.32128  0.44467  0.327915   \n",
       "4  0.704268  0.178193  0.247408  0.24564  0.22089  0.21230  0.204687   \n",
       "\n",
       "     cont12    cont13    cont14  \n",
       "0  0.594646  0.822493  0.714843  \n",
       "1  0.366307  0.611431  0.304496  \n",
       "2  0.373424  0.195709  0.774425  \n",
       "3  0.321570  0.605077  0.602642  \n",
       "4  0.202213  0.246011  0.432606  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_finalFeatures_df = pd.DataFrame(train_feature_df, columns = finalFeatures)\n",
    "X_finalFeatures_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328.59944499\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.Ridge (alpha = 0.5)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_finalFeatures_df, y_train, test_size = 0.33, random_state = 42)\n",
    "reg.fit(X_train1, y_train1)\n",
    "\n",
    "predictions = reg.predict(X_test1)\n",
    "RR_mae = mean_absolute_error(y_test1, predictions)\n",
    "print(mean_absolute_error(y_test1, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328.2302849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeet\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Lasso(alpha = 0.1)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_finalFeatures_df, y_train, test_size = 0.33, random_state = 42)\n",
    "clf.fit(X_train1, y_train1)\n",
    "\n",
    "predictions = clf.predict(X_test1)\n",
    "Lasso_mae = mean_absolute_error(y_test1, predictions)\n",
    "print(mean_absolute_error(y_test1, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328.2302849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_finalFeatures_df, y_train, test_size = 0.33, random_state = 42)\n",
    "\n",
    "regressor.fit(X_train1, y_train1)\n",
    "\n",
    "predicitons = regressor.predict(X_test1)\n",
    "DTR_mae = mean_absolute_error(y_test1, predictions)\n",
    "print(mean_absolute_error(y_test1, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755.37111047\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBRegressor()\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_finalFeatures_df, y_train, test_size = 0.33, random_state = 42)\n",
    "clf.fit(X_train1, y_train1)\n",
    "\n",
    "predictions = clf.predict(X_test1)\n",
    "XGB_mae = mean_absolute_error(y_test1, predictions)\n",
    "print(mean_absolute_error(y_test1, predicitons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging (Rabdom Forest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315.00823084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_finalFeatures_df, y_train, test_size = 0.33, random_state = 42)\n",
    "\n",
    "clf.fit(X_train1, y_train1)\n",
    "\n",
    "predictions = clf.predict(X_test1)\n",
    "Bagging_mae = mean_absolute_error(y_test1, predictions)\n",
    "print(mean_absolute_error(y_test1, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting (adaBoost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755.37111047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "clf = AdaBoostRegressor()\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_finalFeatures_df, y_train, test_size = 0.33, random_state = 42)\n",
    "\n",
    "clf.fit(X_train1, y_train1)\n",
    "\n",
    "predictions = clf.predict(X_test1)\n",
    "adaboost_mae = mean_absolute_error(y_test1, predicitons)\n",
    "print(mean_absolute_error(y_test1, predicitons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245.29499127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "clf = GradientBoostingRegressor()\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_finalFeatures_df, y_train, test_size = 0.33, random_state = 42)\n",
    "clf.fit(X_train1, y_train1)\n",
    "\n",
    "predictions = clf.predict(X_test1)\n",
    "STGB_mae = mean_absolute_error(y_test1, predictions)\n",
    "print(mean_absolute_error(y_test1, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Models MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEICAYAAACnL3iHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a785c10470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('Ridge', 'Lasso', 'DTree', 'Bagging', 'Boosting', 'StoGB', 'XGBoost')\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "performance = [RR_mae, Lasso_mae, DTR_mae, Bagging_mae, adaboost_mae, STGB_mae, XGB_mae]\n",
    "\n",
    "plt.bar(y_pos, performance, align = 'center', alpha = 0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Mean Aabsolute Error')\n",
    "plt.title('Models Comparison for 130 Features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
